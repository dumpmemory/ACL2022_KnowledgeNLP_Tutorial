# ACL2022_KnowledgeNLP_Tutorial

Materials for ACL-2022 tutorial: Knowledge-Augmented Methods for Natural Language Processing

# Presenters
[Chenguang Zhu](https://www.microsoft.com/en-us/research/people/chezhu/), Microsoft Cognitive Services Research

[Yichong Xu](https://www.microsoft.com/en-us/research/people/yicxu/), Microsoft Cognitive Services Research

[Xiang Ren](https://shanzhenren.github.io/), University of Southern California

[Bill Yuchen Lin](https://yuchenlin.xyz/), University of Southern California

[Meng Jiang](http://www.meng-jiang.com/), University of Notre Dame

[Wenhao Yu](https://wyu97.github.io/), University of Notre Dame

# Abstract
Knowledge in NLP has been a rising trend especially after the advent of large scale pre-trained models. NLP models with attention to knowledge can i) access unlimited amount of external information; ii) delegate the task of storing knowledge from its parameter space to knowledge sources; iii) obtain up-to-date information; iv) make prediction results more explainable via selected knowledge. In this tutorial, we will introduce the key steps in integrating knowledge into NLP, including knowledge grounding from text, knowledge representation and fusing. We will also introduce recent state-of-the-art applications in fusing knowledge into language understanding, language generation and commonsense reasoning.

